# modules/scrap.py

import streamlit as st
import requests 
from bs4 import BeautifulSoup
import pandas as pd
import re
import os # A√∫n se necesita para Playwright, no importa si se usa o no expl√≠citamente


from playwright.sync_api import sync_playwright # <-- Importar Playwright

# URL objetivo de Live Score
LIVE_SCORE_URL = "https://live18.nowgoal25.com/" 
# ¬°IMPORTANTE! Verificar manualmente si el subdominio (live18) cambia, ya que afecta la accesibilidad.


def fetch_html_with_playwright(url):
    """
    Descarga el contenido HTML de la URL usando Playwright para ejecutar JavaScript.
    """
    st.info(f"üåê Iniciando navegador headless para descargar: `{url}`")
    html_content = None
    browser = None # Inicializar a None para asegurar que se cierre en `finally`

    try:
        with sync_playwright() as p:
            # Opci√≥n para lanzar Chromium
            # Playwright autom√°ticamente usar√° PLAYWRIGHT_BROWSERS_PATH si est√° definido en el entorno.
            # No se necesita `executable_path` aqu√≠.
            browser = p.chromium.launch(
                headless=True, # Modo sin interfaz gr√°fica
                args=[
                    '--no-sandbox',               # Crucial para entornos de contenedores como Streamlit Cloud
                    '--disable-setuid-sandbox',   # Seguridad
                    '--disable-dev-shm-usage',    # Resuelve problemas de memoria en Docker/contenedores
                    '--single-process'            # Para conservar recursos en entornos con RAM limitada
                ],
            )
            page = browser.new_page()
            
            st.write(f"Depuraci√≥n Playwright: Navegando a la URL: {url} (Timeout: 60s, Esperando red inactiva)...")
            page.goto(url, timeout=60000, wait_until='networkidle') # wait_until='networkidle' es clave: espera que no haya nuevas solicitudes de red por un tiempo.

            st.write("Depuraci√≥n Playwright: Esperando que la tabla principal (`table#table_live`) sea visible (Timeout: 30s)...")
            try:
                # Aseg√∫rate de que este selector CSS sea el correcto si ha cambiado la web.
                # Puedes ajustarlo a, por ejemplo: 'div#mintable table' si 'table#table_live' es inestable.
                page.wait_for_selector('table#table_live', state='visible', timeout=30000) 
                st.success("‚úÖ Depuraci√≥n Playwright: ¬°Tabla principal (`table#table_live`) detectada en el DOM y es visible!")
            except Exception as e:
                st.warning(f"‚ö†Ô∏è Depuraci√≥n Playwright: ¬°ADVERTENCIA! La tabla `table#table_live` NO apareci√≥ a tiempo o no es visible: {e}")
                st.write("Se continuar√° con el HTML disponible para depuraci√≥n. Esto podr√≠a ser el motivo si no se encuentran partidos.")
                
            html_content = page.content() # Obtener el HTML renderizado (con JS ejecutado)
            st.success("‚úÖ Contenido HTML renderizado descargado con √©xito.")
            return html_content
            
    except Exception as e:
        st.error(f"‚ùå Error cr√≠tico con Playwright: {e}")
        st.info("üí° Este error se da al intentar lanzar el navegador de Playwright.")
        st.markdown("**Por favor, revisa el c√≥digo `start.sh` de tu repositorio.** Es lo m√°s importante. Aseg√∫rate de que:")
        st.markdown("- Contenga `playwright install chromium --with-deps --install-dir \"$PLAYWRIGHT_BROWSERS_PATH\"`.")
        st.markdown("- Contenga `export PLAYWRIGHT_BROWSERS_PATH=\"$(pwd)/.playwright_browsers\"`.")
        st.markdown("- Los pasos se ejecuten en el orden correcto.")
        st.markdown("- Tu repositorio de GitHub no tenga archivos inesperados (`.gitignore` suele excluir `.playwright_browsers`).")
        return None
    finally:
        if browser: 
            try:
                browser.close()
                st.write("Depuraci√≥n Playwright: Navegador Playwright cerrado.")
            except Exception as close_e:
                st.warning(f"Depuraci√≥n Playwright: Error al cerrar el navegador en el `finally` block: {close_e}")


# --- is_upcoming_match, clean_team_name, y scrape_upcoming_matches_logic se mantienen. ---
# Simplemente a√±ade el c√≥digo restante de la versi√≥n anterior debajo de estas funciones.

def clean_team_name(team_name_raw):
    """Limpia el nombre del equipo, removiendo cualquier anotaci√≥n de ranking (ej. "[LIT D1-8]") o neutralidad "(N)", etc."""
    cleaned_name = re.sub(r'\[[^\]]*\]', '', team_name_raw) 
    cleaned_name = re.sub(r'\s*\(\s*[Nn]\s*\)', '', cleaned_name)
    cleaned_name = re.sub(r'\s*\([^)]*\)\s*', '', cleaned_name) 
    return cleaned_name.strip()

def is_upcoming_match(status_td_content, status_td_title):
    """Determina si un partido est√° "por comenzar" bas√°ndose en el texto de su celda de estado y su atributo `title`."""
    status_text_lower = status_td_content.lower()
    status_title_lower = status_td_title.lower()
    live_or_finished_regex = re.compile(r'^\d+(\+\d+)?\s*(min)?$|^\s*(ht|ft|canc|postp|susp|live|aet|pen|pau|aban|int)\s*$', re.IGNORECASE)

    if live_or_finished_regex.search(status_text_lower):
        st.write(f"  - Descartado (Estado del TD indica activo/finalizado/etc.): `'{status_text_lower}'` coincide con un patr√≥n excluyente.")
        return False
    
    if 'half' in status_title_lower or 'finished' in status_title_lower or 'postponed' in status_title_lower or 'cancelled' in status_title_lower or 'in-play' in status_title_lower or 'suspended' in status_title_lower or 'interrupted' in status_title_lower or 'abandoned' in status_title_lower or 'fulltime' in status_title_lower:
        st.write(f"  - Descartado (T√≠tulo del TD indica activo/finalizado/etc.): `'{status_title_lower}'` coincide con un patr√≥n excluyente.")
        return False
        
    if status_td_content == '' and status_td_title == '':
        st.write(f"  ‚úÖ ¬°CONFIRMADO! Contenido de estado (`'{status_td_content}'`) y t√≠tulo (`'{status_td_title}'`) de TD de estado est√°n ambos vac√≠os. Esto indica un partido PROGRAMADO.")
        return True
    
    st.write(f"  - Ambiguo/Desconocido: Estado `{status_td_content}` / T√≠tulo `{status_td_title}`. No se clasifica como PROGRAMADO ni se descart√≥ expl√≠citamente.")
    return False

def scrape_upcoming_matches_logic(html_content_raw):
    """Extrae los IDs, nombres de equipos, y horas de los partidos que A√öN NO HAN COMENZADO."""
    st.markdown("---") 
    st.subheader("üïµÔ∏è‚Äç‚ôÇÔ∏è **Registro Detallado de la Extracci√≥n de Partidos de NowGoal:**")
    st.markdown("---") 

    soup = BeautifulSoup(html_content_raw, 'html.parser')
    upcoming_matches_data = []
    main_match_table = None

    st.write("Depuraci√≥n: Intentando localizar la tabla principal por ID `table_live`...")
    main_match_table = soup.find('table', id='table_live')

    if not main_match_table:
        st.write("Depuraci√≥n: ID `table_live` NO ENCONTRADO. Intentando una b√∫squeda m√°s robusta por patrones de contenido (`scoretitle` y `tds` classes).")
        all_tables = soup.find_all('table')
        if not all_tables:
            st.error("‚ùå ERROR: No se encontr√≥ NINGUNA etiqueta `<table>` en el HTML analizado.")
            st.warning("Esto es cr√≠tico y sugiere que el HTML est√° vac√≠o o no contiene tablas de partidos.")
            return []

        for table in all_tables:
            if table.find('tr', class_='scoretitle') and table.find('tr', class_='tds'):
                main_match_table = table
                st.success(f"üéâ **√âxito!** Tabla principal encontrada por sus clases de fila. ID: `{table.get('id', 'N/A')}`, Clases: `{table.get('class', 'N/A')}`.")
                break 
        
        if not main_match_table:
            st.error("‚ùå ERROR CR√çTICO: No se encontr√≥ la tabla principal de partidos ni por ID espec√≠fico (`table_live`) ni por la combinaci√≥n de clases (`scoretitle` y `tds`).")
            st.warning("Esto indica un cambio MUY significativo en la estructura del HTML o que el contenido relevante a√∫n no est√° en el HTML recibido. Revisa el HTML RAW descargado para ver el contenido real.")
            return []

    st.success("‚úÖ **Tabla principal de partidos localizada.**")

    found_result_split = False
    rows_processed_count = 0
    upcoming_matches_count = 0

    all_trs_in_table = main_match_table.find_all('tr', recursive=False)
    
    if not all_trs_in_table:
        st.warning("Depuraci√≥n: La tabla de partidos encontrada est√° vac√≠a o no contiene filas `<tr>` directas. ¬°Inesperado! (¬øLa tabla se carg√≥, pero sin datos?)")
        return []

    st.info(f"Depuraci√≥n: Iniciando an√°lisis de {len(all_trs_in_table)} filas dentro de la tabla...")

    for row in all_trs_in_table:
        rows_processed_count += 1
        row_id = row.get('id', 'No ID')
        row_classes = row.get('class', [])
        
        st.write(f"\n--- **Procesando Fila {rows_processed_count}: ID=`{row_id}`, Clases=`{row_classes}`** ---")

        if 'result-split' in row_classes or row_id == 'resultSplit':
            found_result_split = True
            st.info("Depuraci√≥n: Detectado el separador de Resultados (`resultSplit`). Las siguientes filas ser√°n consideradas RESULTADOS y no 'Programados'.")
            continue

        if found_result_split:
            st.write("Depuraci√≥n: Saltando fila, ya que se encontr√≥ `resultSplit` anteriormente. Esta fila es un partido TERMINADO.")
            continue

        if 'Leaguestitle' in row_classes or 'adtext-bg' in row_classes or 'ad_m' in row_classes or (row_id.startswith('tr3_') and not row.get('matchid')): 
            st.write("Depuraci√≥n: Saltando fila: No es una fila de partido principal (puede ser t√≠tulo de liga, anuncio, o metadatos irrelevantes).")
            continue

        if 'tds' in row_classes:
            match_id = row.get('matchid')

            if not match_id:
                st.warning(f"Depuraci√≥n: Fila `tds` {rows_processed_count} no tiene 'matchid'. Esto es inesperado para una fila de partido. Contenido: `{row.get_text(strip=True)[:100]}`. Saltando.")
                continue 

            status_td = row.find('td', id=f'time_{match_id}', class_='status') 
            if not status_td:
                st.warning(f"¬°ADVERTENCIA! Para Partido ID `{match_id}` (Fila {rows_processed_count}), no se encontr√≥ la celda de estado (`id=time_{match_id}`, class=`status`). Sin esto, no podemos clasificarlo. Saltando.")
                st.write(f"Raw HTML de esta fila de partido para depuraci√≥n (porci√≥n): `{str(row)[:500]}`") 
                continue
            
            time_data_td = row.find('td', {'name': 'timeData'})

            status_text_clean = status_td.get_text(strip=True)
            status_title_clean = status_td.get('title', '').strip()
            current_time_text_raw = time_data_td.get_text(strip=True) if time_data_td else "Hora_TD_N/A" 

            st.write(f"  **- Clasificando Partido ID `{match_id}`:**")
            st.write(f"    - `status_td` Contenido (limpio): `'{status_text_clean}'`")
            st.write(f"    - `status_td` Atributo `title` (limpio): `'{status_title_clean}'`")
            st.write(f"    - `timeData_td` Contenido (hora visible, ej. `19:00`): `'{current_time_text_raw}'`")

            if is_upcoming_match(status_text_clean, status_title_clean):
                upcoming_matches_count += 1
                
                home_team_tag = row.find('a', id=f'team1_{match_id}')
                away_team_tag = row.find('a', id=f'team2_{match_id}')
                
                home_team_name = clean_team_name(home_team_tag.get_text(strip=True)) if home_team_tag else f"Local {match_id} (No Tag A)"
                away_team_name = clean_team_name(away_team_tag.get_text(strip=True)) if away_team_tag else f"Visitante {match_id} (No Tag A)"
                
                match_time_utc = time_data_td.get('data-t') if time_data_td else "Hora_UTC_N/A" 
                
                st.success(f"  üéâ **¬°PARTIDO PROGRAMADO ENCONTRADO!** ID: `{match_id}` - `{home_team_name}` vs `{away_team_name}` (Hora Visible: {current_time_text_raw})")

                upcoming_matches_data.append({
                    'id': match_id,
                    'hora_utc': match_time_utc,
                    'hora_visible': current_time_text_raw,
                    'equipo_local': home_team_name,
                    'equipo_visitante': away_team_name
                })
            else:
                st.write(f"  Partido ID `{match_id}` (Fila {rows_processed_count}) descartado como PROGRAMADO.")
        else: 
            st.write(f"Depuraci√≥n: Fila {rows_processed_count} no tiene la clase `tds`. Saltando. (Ej. es una fila de cabecera de liga, un anuncio, etc.)")

    st.markdown("---")
    st.info(f"**An√°lisis Finalizado:** Se revisaron {rows_processed_count} filas. Se encontraron **{upcoming_matches_count}** partidos programados.")
    if upcoming_matches_count == 0:
        st.warning("Si esperabas ver partidos y no se encontr√≥ ninguno, el sitio podr√≠a haber cambiado o no hay partidos programados.")
        st.markdown("---") 
        st.info("Para depuraci√≥n, puedes expandir el HTML RAW que Playwright logr√≥ descargar:")
        if st.checkbox("Mostrar el HTML RAW que Playwright descarg√≥ (puede ser muy grande)"):
            with st.expander("Contenido HTML Raw Completo"):
                st.code(html_content_raw[:10000] + ("\n... [Contenido truncado]" if len(html_content_raw) > 10000 else ""))

    return upcoming_matches_data

# El resto del UI (`scrap()` wrapper) se mantiene igual
def scrap():
    st.header("‚ö° Scraper de Partidos Programados de NowGoal ‚ö°")
    st.markdown("""
    Esta herramienta se conecta a NowGoal.com utilizando un **navegador real** (headless) para ejecutar el JavaScript de la p√°gina
    y extraer los IDs, las horas (UTC y visible), y los nombres de los equipos de los partidos
    que **A√öN NO HAN COMENZADO (est√°n programados)**.
    """)
    st.warning(f"**Aviso:** La URL de NowGoal y su estructura HTML pueden cambiar. Aseg√∫rate de que esta URL est√© actualizada si hay problemas: `{LIVE_SCORE_URL}`")
    st.markdown("---")

    html_content = None
    if st.button("üöÄ ¬°Extraer Partidos Programados Ahora de la Web!"):
        html_content = fetch_html_with_playwright(LIVE_SCORE_URL) 

    if html_content: 
        matches = scrape_upcoming_matches_logic(html_content)

        if matches:
            st.subheader(f"üìä Resumen de Partidos Programados Encontrados: {len(matches)}")
            df = pd.DataFrame(matches)
            st.dataframe(df, use_container_width=True)

            csv = df.to_csv(index=False).encode('utf-8')
            st.download_button(
                label="üíæ Descargar datos como CSV",
                data=csv,
                file_name="partidos_futuros_nowgoal.csv",
                mime="text/csv",
                help="Haz clic para descargar los datos en un archivo CSV."
            )
        else:
            st.error("‚ùå **No se encontraron partidos programados en el HTML descargado.** Revisa los logs de depuraci√≥n para m√°s detalles.")
            st.info("Esto puede significar que: 1) Actualmente no hay partidos programados en la p√°gina. 2) La estructura HTML de NowGoal cambi√≥. 3) Playwright no pudo cargar el contenido.")

    st.markdown("---") 
    st.info("Para problemas persistentes, el [repositorio de Playwright](https://github.com/microsoft/playwright/issues) o la [documentaci√≥n de Streamlit Community Cloud](https://docs.streamlit.io/streamlit-community-cloud/get-started/troubleshooting) pueden ser de ayuda.")
